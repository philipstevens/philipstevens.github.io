---
title: "About"
layout: single
permalink: /about/
description: "Phil Stevens helps teams ship LLM workflows to production with eval gating, release discipline, and failure-mode coverage. 12 years applied ML, consulting since 2023."
author_profile: true
profile_page: true
last_updated: 2026-02-12
---

[Email me](mailto:philipstevens4@gmail.com){: .btn .btn--primary }

Most teams shipping AI into production don't have a reliability problem — they have a measurement problem. They can't define what "good" looks like, so they can't tell when things break.

I help fix that. I'm Phil Stevens, a foundation model engineer focused on making LLM workflows reliable, measurable, and safe to ship. I bring 12 years of applied ML across personalization, NLP, and real-time systems (Agoda, Quantcast), and have been consulting independently since 2023 on production LLM reliability: eval design, release gating, RAG hardening, and drift detection.

My work typically spans the full stack: data pipelines, model selection and adaptation, evaluation design, and production hardening. I've built systems end-to-end and also parachuted into teams that needed a specific piece fixed.

I publish case studies and technical write-ups here to share how I approach this work.

## Where to go next

- [Services](/) — engagement options and pricing
- [Library](/library/) — case studies and tutorials
- [CV](/cv/) — full background

{% include last-updated.html %}
